{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb0615b-79c1-4df1-8bb7-7e7fa966cec6",
   "metadata": {},
   "source": [
    "Huggingface part, put this in app.py in filed pulled from huggingface by\n",
    "\n",
    " When prompted for a password, use an access token with write permissions.\n",
    "Generate one from your settings: https://huggingface.co/settings/tokens\n",
    "git clone https://huggingface.co/spaces/felixfritzen/project\n",
    "Modify the files locally, then commit and push:\n",
    "\n",
    "\n",
    " git commit -am \"Update space\"\n",
    " \n",
    " git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a84ae39d-18a9-4d3f-8612-fbfd3ec49e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 00:24:29,064 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2024-12-13 00:24:29,073 INFO: Initializing external client\n",
      "2024-12-13 00:24:29,076 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2024-12-13 00:24:30,158 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1163414\n",
      "Model downloaded to: /var/tmp/b51ff6d0-232a-4592-98aa-3cf490f4be17/KMeans_Model/1\n",
      "2024-12-13 00:24:32,986 INFO: Use pytorch device_name: cpu\n",
      "2024-12-13 00:24:32,987 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.53s) \n",
      "(14220, 384) (14220,)\n",
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "2024-12-13 00:24:40,676 INFO: HTTP Request: GET http://127.0.0.1:7882/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-12-13 00:24:40,686 INFO: HTTP Request: HEAD http://127.0.0.1:7882/ \"HTTP/1.1 200 OK\"\n",
      "2024-12-13 00:24:40,737 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-12-13 00:24:41,286 INFO: HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://9913fd8374700f8836.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "2024-12-13 00:24:42,622 INFO: HTTP Request: HEAD https://9913fd8374700f8836.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9913fd8374700f8836.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import hopsworks\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gradio as gr\n",
    "\n",
    "project = hopsworks.login(api_key_value=\"wOWQmzzHeITT5wlJ.FkOButuQ3XpDXSUO1LnTuaNfD7SPWolfF1hateoistsLFFsBF7upULn5z6qKPOIB\")\n",
    "fs = project.get_feature_store() \n",
    "mr = project.get_model_registry()\n",
    "\n",
    "model = mr.get_model(\"KMeans_Model\", version=1)\n",
    "model_dir = model.download()\n",
    "print(f\"Model downloaded to: {model_dir}\")\n",
    "with open(f\"{model_dir}/kmeans_model.pkl\", \"rb\") as f:\n",
    "    kmeans_model = pickle.load(f)\n",
    "\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#encoded_headlines = model.encode(headline_df['title'].to_list())\n",
    "#loaded from hopsworks!\n",
    "fg_vectors = fs.get_feature_group(\n",
    "    name='high_dimensional_vectors', \n",
    "    version=2,\n",
    ")\n",
    "retrieved_data = fg_vectors.read()\n",
    "vectors = retrieved_data[[f\"dim_{i}\" for i in range(384)]].to_numpy()\n",
    "headlines = retrieved_data['headlines']\n",
    "print(vectors.shape, headlines.shape)\n",
    "\n",
    "def df_between_dates(df, start_date, end_date):\n",
    "    return df[(df['pubdate'] >= start_date) & (df['pubdate'] <= end_date)]\n",
    "\n",
    "def get_most_similar_headlines(query_embedding, embeddings, headlines, top_n=5):\n",
    "    print('compute similarities')\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_indices = np.argsort(-similarities)[:top_n]\n",
    "    return [(headlines[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "def compare(encoded_headlines, headlines, query, kmeans_model, text_model):\n",
    "    encoding = text_model.encode([query])\n",
    "    most_similar = get_most_similar_headlines(encoding, encoded_headlines, headlines, top_n=5)\n",
    "    cluster = kmeans_model.predict(encoding)\n",
    "    print(f\"Query: {query}\")\n",
    "    print()\n",
    "    outp = \"\"\n",
    "    outp += str(f\"Cluster: {cluster[0]}\")\n",
    "    outp += \"\\nMost Similar Headlines:\"\n",
    "    \n",
    "    for i, (headline, similarity) in enumerate(most_similar, 1):\n",
    "        outp +=f\"\\n{i}. {headline} (Similarity: {similarity:.4f})\"\n",
    "    return str(outp)\n",
    "        \n",
    "def apply_kmean(prompt):\n",
    "    return compare(vectors, headlines, prompt, kmeans_model, text_model)\n",
    "\n",
    "with gr.Blocks(css=\".gradio-container {background-color: white;}\") as demo:\n",
    "    gr.Markdown(\"### Headline prediction app\")\n",
    "    text_input = gr.Textbox(label=\"Enter your headline:\")\n",
    "    text_output = gr.Textbox(label=\"Most simmilar headlines:\")\n",
    "    gr.Button(\"Predict headlines\").click(apply_kmean, inputs=text_input, outputs=text_output)\n",
    "    gr.HTML('<iframe src=\"https://felixfritzen.github.io/Scalable_proj/\" width=\"100%\" height=\"100%\" style=\"border:none;\"></iframe>')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de49db-5aa4-45f3-9453-a3b1159033fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
