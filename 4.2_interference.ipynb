{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb0615b-79c1-4df1-8bb7-7e7fa966cec6",
   "metadata": {},
   "source": [
    "Huggingface part, put this in app.py in filed pulled from huggingface by\n",
    "\n",
    " When prompted for a password, use an access token with write permissions.\n",
    "Generate one from your settings: https://huggingface.co/settings/tokens\n",
    "git clone https://huggingface.co/spaces/felixfritzen/project\n",
    "Modify the files locally, then commit and push:\n",
    "\n",
    "\n",
    " git commit -am \"Update space\"\n",
    " \n",
    " git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84ae39d-18a9-4d3f-8612-fbfd3ec49e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-30 10:36:56,328 INFO: HTTP Request: GET https://api.gradio.app/gradio-messaging/en \"HTTP/1.1 200 OK\"\n",
      "2024-12-30 10:36:58,008 INFO: Initializing external client\n",
      "2024-12-30 10:36:58,010 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2024-12-30 10:36:59,171 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1163414\n",
      "Model downloaded to: /var/tmp/c02073b5-961b-447b-a93b-c843109dafb1/KMeans_Model/1\n",
      "2024-12-30 10:37:01,417 INFO: Use pytorch device_name: cpu\n",
      "2024-12-30 10:37:01,418 INFO: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.5.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.70s) \n",
      "(13424, 384) (13424,)\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "2024-12-30 10:37:09,006 INFO: HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-12-30 10:37:09,052 INFO: HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2024-12-30 10:37:09,076 INFO: HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-12-30 10:37:09,635 INFO: HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n",
      "2024-12-30 10:37:09,698 INFO: HTTP Request: GET https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64 \"HTTP/1.1 200 OK\"\n",
      "* Running on public URL: https://d02b5c6a799aed656d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "2024-12-30 10:37:11,166 INFO: HTTP Request: HEAD https://d02b5c6a799aed656d.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d02b5c6a799aed656d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import hopsworks\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gradio as gr\n",
    "\n",
    "project = hopsworks.login(api_key_value=\"wOWQmzzHeITT5wlJ.FkOButuQ3XpDXSUO1LnTuaNfD7SPWolfF1hateoistsLFFsBF7upULn5z6qKPOIB\")\n",
    "fs = project.get_feature_store() \n",
    "mr = project.get_model_registry()\n",
    "\n",
    "model = mr.get_model(\"KMeans_Model\", version=1)\n",
    "model_dir = model.download()\n",
    "print(f\"Model downloaded to: {model_dir}\")\n",
    "with open(f\"{model_dir}/kmeans_model.pkl\", \"rb\") as f:\n",
    "    kmeans_model = pickle.load(f)\n",
    "\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#encoded_headlines = model.encode(headline_df['title'].to_list())\n",
    "#loaded from hopsworks!\n",
    "fg_vectors = fs.get_feature_group(\n",
    "    name='headlinesemb', \n",
    "    version=1,\n",
    ")\n",
    "retrieved_data = fg_vectors.read()\n",
    "vectors = retrieved_data[[f\"dim_{i}\" for i in range(384)]].to_numpy()\n",
    "headlines = retrieved_data['headlines']\n",
    "print(vectors.shape, headlines.shape)\n",
    "\n",
    "def df_between_dates(df, start_date, end_date):\n",
    "    return df[(df['pubdate'] >= start_date) & (df['pubdate'] <= end_date)]\n",
    "\n",
    "def get_most_similar_headlines(query_embedding, embeddings, headlines, top_n=5):\n",
    "    print('compute similarities')\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_indices = np.argsort(-similarities)[:top_n]\n",
    "    return [(headlines[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "def compare(encoded_headlines, headlines, query, kmeans_model, text_model):\n",
    "    encoding = text_model.encode([query])\n",
    "    most_similar = get_most_similar_headlines(encoding, encoded_headlines, headlines, top_n=5)\n",
    "    cluster = kmeans_model.predict(encoding)\n",
    "    print(f\"Query: {query}\")\n",
    "    print()\n",
    "    outp = \"\"\n",
    "    outp += str(f\"Cluster: {cluster[0]}\")\n",
    "    outp += \"\\nMost Similar Headlines:\"\n",
    "    \n",
    "    for i, (headline, similarity) in enumerate(most_similar, 1):\n",
    "        outp +=f\"\\n{i}. {headline} (Similarity: {similarity:.4f})\"\n",
    "    return str(outp)\n",
    "        \n",
    "def apply_kmean(prompt):\n",
    "    return compare(vectors, headlines, prompt, kmeans_model, text_model)\n",
    "\n",
    "with gr.Blocks(css=\".gradio-container {background-color: white;}\") as demo:\n",
    "    gr.Markdown(\"# Headline prediction app, [clustering page](https://felixfritzen.github.io/Scalable_proj/)\")\n",
    "    text_input = gr.Textbox(label=\"Enter your headline:\")\n",
    "    text_output = gr.Textbox(label=\"Most simmilar headlines:\")\n",
    "    gr.Button(\"Predict headlines\").click(apply_kmean, inputs=text_input, outputs=text_output)\n",
    "    gr.HTML('<iframe src=\"https://felixfritzen.github.io/Scalable_proj/\" width=\"100%\" height=\"100%\" style=\"border:none;\"></iframe>', min_height=50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
